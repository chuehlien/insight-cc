## Summary

The goal of this challenge is to implement two features:

1. Calculate the total number of times each word has been tweeted.
2. Calculate the median number of *unique* words per tweet, and update this median as tweets come in. 


## Requirements

This solution requires the intallation of 'numpy' library.


## Misc

Additional text files have been generated via Ruby for testing purposes. Only 'second.txt' was included due to the size of the other files. 'second.txt' contains 6000 lines of randomly chosen words from the dictionary, with each line of varying length in words. [2](http://www.skorks.com/2010/03/how-to-quickly-generate-a-large-file-on-the-command-line-with-linux/)

	├── README.md  
	├── run.sh  
	├── src  
	│   ├── median_unique.py  
	│   └── words_tweeted.py  
	├── tweet_input  
	│   ├── tweets.txt
	│   ├── second.txt  
	└── tweet_output  
	    ├── ft1.txt  
	    └── ft2.txt  










